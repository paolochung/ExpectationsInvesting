{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aa13e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully exported inventory history to inventory_history.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "def process_inventory(transaction_path, product_map_path, output_path):\n",
    "    # Load and merge data\n",
    "    transactions = pd.read_csv(transaction_path)\n",
    "    product_map = pd.read_csv(product_map_path).set_index('product_id')['product_name']\n",
    "    \n",
    "    # Filter only investment transactions and relevant columns\n",
    "    investments = transactions[\n",
    "        (transactions['TRANSACTION_TYPE'] == 'INVESTMENT') & \n",
    "        (transactions['TYPE'].isin(['BUY', 'SELL']))\n",
    "    ][['T_DATE', 'PRODUCT_ID', 'TYPE', 'UNIT']].copy()\n",
    "    \n",
    "    # Convert dates to datetime and sort\n",
    "    investments['T_DATE'] = pd.to_datetime(investments['T_DATE'])\n",
    "    investments = investments.sort_values('T_DATE')\n",
    "    \n",
    "    # Initialize tracking structures\n",
    "    inventory = defaultdict(int)\n",
    "    history = []\n",
    "    current_quantities = {}\n",
    "\n",
    "    for idx, row in investments.iterrows():\n",
    "        product_id = row['PRODUCT_ID']\n",
    "        action = row['TYPE']\n",
    "        units = row['UNIT']\n",
    "        \n",
    "        # Update inventory\n",
    "        if action == 'BUY':\n",
    "            inventory[product_id] += units\n",
    "        elif action == 'SELL':\n",
    "            inventory[product_id] = max(0, inventory[product_id] - units)\n",
    "        \n",
    "        # Get product name\n",
    "        product_name = product_map.get(product_id, f'Unknown Product {product_id}')\n",
    "        \n",
    "        # Record history\n",
    "        history.append({\n",
    "            'Date': row['T_DATE'].strftime('%Y-%m-%d'),\n",
    "            'Product_ID': product_id,\n",
    "            'Product_Name': product_name,\n",
    "            'Transaction_Type': action,\n",
    "            'Units': units,\n",
    "            'Cumulative_Quantity': inventory[product_id]\n",
    "        })\n",
    "        \n",
    "        # Track current quantity for potential optimization\n",
    "        current_quantities[product_id] = inventory[product_id]\n",
    "\n",
    "    # Create DataFrame and merge with product names\n",
    "    result = pd.DataFrame(history)\n",
    "    \n",
    "    # Add product name to results\n",
    "    result['Product_Name'] = result['Product_ID'].map(product_map)\n",
    "    \n",
    "    # Handle unknown products\n",
    "    result['Product_Name'] = result['Product_Name'].fillna(result['Product_ID'].apply(\n",
    "        lambda x: f'Unknown Product {x}'))\n",
    "    \n",
    "    # Select final columns\n",
    "    final_output = result[[\n",
    "        'Date', 'Product_ID', 'Product_Name', \n",
    "        'Transaction_Type', 'Units', 'Cumulative_Quantity'\n",
    "    ]]\n",
    "    \n",
    "    # Save to CSV\n",
    "    final_output.to_csv(output_path, index=False)\n",
    "    print(f\"Successfully exported inventory history to {output_path}\")\n",
    "    return final_output\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    transaction_file = \"transaction_path.csv\"\n",
    "    product_map_file = \"product_id_to_name.csv\"\n",
    "    output_file = \"inventory_history.csv\"\n",
    "    \n",
    "    inventory_history = process_inventory(transaction_file, product_map_file, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec651e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported inventory_history_by_product.csv\n",
      "    Product_ID                  Product_Name        Date Transaction_Type  \\\n",
      "0      1009100                         3M Co  2021-06-29              BUY   \n",
      "1      1009100                         3M Co  2025-03-26             SELL   \n",
      "2      1046315                58.COM INC-ADR  2018-02-28              BUY   \n",
      "3      1046315                58.COM INC-ADR  2020-04-30             SELL   \n",
      "4      1046198  AAC TECHNOLOGIES HOLDINGS IN  2017-02-28              BUY   \n",
      "5      1046198  AAC TECHNOLOGIES HOLDINGS IN  2017-05-02             SELL   \n",
      "6      1050536   ACADIA Pharmaceuticals Inc   2025-01-21              BUY   \n",
      "7      1050536   ACADIA Pharmaceuticals Inc   2025-01-21              BUY   \n",
      "8      1046394                      ACER INC  2018-01-02              BUY   \n",
      "9      1046394                      ACER INC  2018-01-02              BUY   \n",
      "10     1046394                      ACER INC  2018-05-02              BUY   \n",
      "11     1046394                      ACER INC  2023-03-31             SELL   \n",
      "12     1050416             ACI Worldwide Inc  2025-01-21              BUY   \n",
      "13     1050416             ACI Worldwide Inc  2025-01-21              BUY   \n",
      "14     1012338                 AIA Group Ltd  2021-05-17              BUY   \n",
      "15     1012338                 AIA Group Ltd  2023-03-31             SELL   \n",
      "16     1012338                 AIA Group Ltd  2023-04-01              BUY   \n",
      "17     1012338                 AIA Group Ltd  2023-04-01              BUY   \n",
      "18     1012338                 AIA Group Ltd  2023-04-01              BUY   \n",
      "19     1012338                 AIA Group Ltd  2025-01-20             SELL   \n",
      "\n",
      "         Units  Cumulative_Quantity  \n",
      "0      25099.0              25099.0  \n",
      "1      25099.0                  0.0  \n",
      "2      22925.0              22925.0  \n",
      "3      22925.0                  0.0  \n",
      "4     187903.0             187903.0  \n",
      "5     187903.0                  0.0  \n",
      "6         27.0                 27.0  \n",
      "7     193082.0             193109.0  \n",
      "8    2206740.0            2206740.0  \n",
      "9    3966133.0            6172873.0  \n",
      "10   4101649.0           10274522.0  \n",
      "11  10274522.0                  0.0  \n",
      "12        34.0                 34.0  \n",
      "13    243141.0             243175.0  \n",
      "14    194879.0             194879.0  \n",
      "15    194879.0                  0.0  \n",
      "16    194879.0             194879.0  \n",
      "17    194879.0             389758.0  \n",
      "18    477749.0             867507.0  \n",
      "19     59569.0             807938.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load files\n",
    "product_df = pd.read_csv(\"product_id_to_name.csv\")\n",
    "txn_df = pd.read_csv(\"transaction_path.csv\")\n",
    "\n",
    "# Filter only investment transactions\n",
    "txn = txn_df[txn_df['TRANSACTION_TYPE'] == 'INVESTMENT'].copy()\n",
    "\n",
    "# Only keep relevant columns\n",
    "txn = txn[['T_DATE', 'PRODUCT_ID', 'TYPE', 'UNIT']]\n",
    "\n",
    "# Convert date to datetime for sorting and processing\n",
    "txn['T_DATE'] = pd.to_datetime(txn['T_DATE'], errors='coerce')\n",
    "\n",
    "# Sort by product and date\n",
    "txn = txn.sort_values(['PRODUCT_ID', 'T_DATE'])\n",
    "\n",
    "# Prepare mapping from product_id to name\n",
    "product_map = dict(zip(product_df['product_id'], product_df['product_name']))\n",
    "\n",
    "# Track cumulative quantity for each product\n",
    "records = []\n",
    "cumulative = {}\n",
    "\n",
    "for row in txn.itertuples(index=False):\n",
    "    date, pid, typ, unit = row\n",
    "    if pd.isnull(pid) or pd.isnull(unit):  # skip bad rows\n",
    "        continue\n",
    "    pid = int(pid)\n",
    "    unit = float(unit)\n",
    "    prev = cumulative.get(pid, 0)\n",
    "    if typ == 'BUY':\n",
    "        new = prev + unit\n",
    "    elif typ == 'SELL':\n",
    "        new = prev - unit\n",
    "    else:\n",
    "        continue\n",
    "    cumulative[pid] = new\n",
    "    records.append({\n",
    "        'Product_ID': pid,\n",
    "        'Product_Name': product_map.get(pid, f'Unknown Product {pid}'),\n",
    "        'Date': date.strftime('%Y-%m-%d'),\n",
    "        'Transaction_Type': typ,\n",
    "        'Units': unit,\n",
    "        'Cumulative_Quantity': new\n",
    "    })\n",
    "\n",
    "# Create DataFrame and sort by Product_Name, then Date\n",
    "result = pd.DataFrame(records)\n",
    "result = result.sort_values(['Product_Name', 'Date']).reset_index(drop=True)\n",
    "\n",
    "# Save to CSV\n",
    "result.to_csv(\"inventory_history_by_product.csv\", index=False)\n",
    "print(\"Exported inventory_history_by_product.csv\")\n",
    "\n",
    "# Preview\n",
    "print(result.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb05445f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: 'POSCO Holdings' → 'VIPSHOP HOLDINGS' (73%)\n",
      "Review: 'Kakao' → 'KAKAO CORP' (67%)\n",
      "Review: 'LGELECTRONICS' → 'LG ELECTRONICS INC' (71%)\n",
      "Review: 'NAVER' → 'NAVER CORP' (67%)\n",
      "Review: 'SK hynix' → 'SK HYNIX INC' (80%)\n",
      "Review: 'DAEWOONG PHARM' → 'Daewoong Pharmaceutical Co Ltd' (64%)\n",
      "Review: 'KIA CORP.' → 'KT CORP' (80%)\n",
      "Review: 'HyundaiMtr' → 'HYUNDAI MOTOR' (87%)\n",
      "Review: 'LOTTE SHOPPING' → 'LOTTE SHOPPING LTD' (88%)\n",
      "Review: 'PETROCHINA' → 'PetroChina Co. Ltd.' (74%)\n",
      "Review: 'MTR CORPORATION' → 'S-1 CORPORATION' (83%)\n",
      "Review: 'HSBC HOLDINGS' → 'HSBC Holdings PLC' (87%)\n",
      "Review: 'KINGSOFT' → 'KINGSOFT CORP LTD' (64%)\n",
      "Review: 'CHINA OILFIELD' → 'CHINA OILFIELD SERVICES-H' (74%)\n",
      "Review: 'PING AN' → 'Amgen Inc' (62%)\n",
      "Review: 'SWIRE PACIFIC A' → 'SWIRE PACIFIC LTD - CL A' (81%)\n",
      "Review: 'NAN YA PLASTIC' → 'NAN YA PLASTICS CORP.' (82%)\n",
      "Review: 'FORMOSA PLASTIC' → 'FORMOSA PLASTICS CORP' (83%)\n",
      "Review: 'CHINA RES LAND' → 'CHINA RESOURCES LAND LTD' (74%)\n",
      "Review: 'UNITED MICRO ELECTRONICS' → 'LG ELECTRONICS INC' (71%)\n",
      "Review: 'CHINA LIFE' → 'China Mobile Limited' (60%)\n",
      "Review: 'CHINA UNICOM' → 'Cigna Corp' (64%)\n",
      "Review: 'CHINA TELECOM' → 'CHINA TELECOM CORP LTD-H' (72%)\n",
      "Review: 'BOC HONG KONG' → 'BOC HONG KONG HOLDINGS LTD' (67%)\n",
      "Review: 'CKH HOLDINGS' → 'CHINA COSCO HOLDINGS-H' (67%)\n",
      "Review: 'NEW WORLD DEV' → 'NEW WORLD DEVELOPMENT' (76%)\n",
      "Review: 'POWER ASSETS' → 'POWER ASSETS HOLDINGS LTD' (65%)\n",
      "Review: 'INNOLUX CORPORATION' → 'INNOLUX CORP' (77%)\n",
      "Review: 'CATCHER TECHNOLOGY' → 'CATCHER TECHNOLOGY CO LTD' (84%)\n",
      "Review: 'TRAVELSKY TECH' → 'TRAVELSKY TECHNOLOGY LTD-H' (72%)\n",
      "Review: 'SINOPEC CORP' → 'Intel Corp' (73%)\n",
      "Review: 'CHINA TAIPING' → 'CHINA TAIPING INSURANCE HOLD' (63%)\n",
      "Review: 'WEICHAI POWER' → 'WEICHAI POWER CO LTD-H' (76%)\n",
      "Review: 'PEGATRON CORPORATION' → 'PEGATRON CORP' (79%)\n",
      "Review: 'CHINA RAIL CONS' → 'China Life Insurance Co. Ltd.' (67%)\n",
      "Review: 'LARGAN PRECISION CO' → 'LARGAN PRECISION LTD' (82%)\n",
      "Review: 'KUNLUN ENERGY' → 'Kunlun Energy Co Ltd' (79%)\n",
      "Review: 'ANTA SPORTS' → 'ANTA SPORTS PRODUCTS LTD.' (63%)\n",
      "Review: 'CHINA RAILWAY' → 'CHINA RAILWAY GROUP LTD H' (68%)\n",
      "Review: 'CM BANK' → 'M&T Bank Corp' (74%)\n",
      "Review: 'CHINA MOBILE' → 'China Mobile Limited' (75%)\n",
      "Review: 'CHINA COMM CONS' → 'CHINA COMMUNICATIONS CONST-H' (71%)\n",
      "Review: 'CNOOC' → 'CNOOC Ltd' (71%)\n",
      "Review: 'CKI HOLDINGS' → 'CHINA COSCO HOLDINGS-H' (67%)\n",
      "Review: 'AVICHINA' → 'AIR CHINA LTD-H' (64%)\n",
      "Review: 'CHINACOMSERVICE' → 'ServiceNow Inc ' (69%)\n",
      "Review: 'LENOVO GROUP' → 'LENOVO GROUP LTD' (86%)\n",
      "Review: 'CTF SERVICES' → 'ServiceNow Inc ' (69%)\n",
      "Review: 'BANKCOMM' → 'M&T Bank Corp' (70%)\n",
      "Review: 'COSCO SHIP PORT' → 'COSCO SHIPPING Ports Ltd' (77%)\n",
      "Review: 'CHINA SHENHUA' → 'CHINA SHENHUA ENERGY CO-H' (70%)\n",
      "Review: 'CHINA STATE CON' → 'CHINA TELECOM CORP LTD-H' (63%)\n",
      "Review: 'HANG LUNG PPT' → 'HANG LUNG PROPERTIES LTD' (70%)\n",
      "Review: 'CONCH VENTURE' → 'Accenture PLC' (62%)\n",
      "Review: 'COSCO SHIP HOLD' → 'CHINA COSCO HOLDINGS-H' (67%)\n",
      "Review: 'KGI FINANCIAL HOLDING CO LTD' → 'YUANTA FINANCIAL HOLDING CO. LTD.' (81%)\n",
      "Review: 'Vipshop Holdings Limited' → 'VIPSHOP HOLDINGS' (80%)\n",
      "Review: 'GAC GROUP' → 'AIA Group Ltd' (64%)\n",
      "Review: 'WHARF HOLDINGS' → 'WHARF HOLDINGS LTD' (88%)\n",
      "Review: 'CHINA JINMAO' → 'CHINA JINMAO HOLDINGS GROUP' (62%)\n",
      "Review: 'HENDERSON LAND' → 'HENDERSON LAND DEVELOPMENT' (70%)\n",
      "Review: 'Microsoft Corporation' → 'Microsoft Corp' (80%)\n",
      "Review: 'Broadcom Inc.' → 'Broadcom Ltd' (75%)\n",
      "Review: 'Comcast Corporation' → 'Cigna Corporation' (78%)\n",
      "Review: 'Walt Disney Company (The)' → 'Walt Disney Co/The' (70%)\n",
      "Review: 'Dow Inc.' → 'Coty Inc' (67%)\n",
      "Review: 'Emerson Electric Company' → 'Emerson Electric Co' (88%)\n",
      "Review: 'Lockheed Martin Corporation' → 'Lockheed Martin Corp' (85%)\n",
      "Review: 'Oracle Corporation' → 'Oracle Corp' (76%)\n",
      "Review: 'Perrigo Company plc' → 'Perrigo Co PLC' (85%)\n",
      "Review: 'QUALCOMM Incorporated' → 'QUALCOMM Inc' (73%)\n",
      "Review: 'Science Applications Internatio' → 'Science Applications International Corp ' (89%)\n",
      "Review: 'Stryker Corporation' → 'S-1 CORPORATION' (79%)\n",
      "Review: 'NCsoft' → 'NCSOFT CORP' (71%)\n",
      "Review: 'SAMSUNG SDS' → 'SAMSUNG SDS CO LTD' (76%)\n",
      "Review: 'KEPCO' → 'KeyCorp' (67%)\n",
      "Review: 'SAMSUNG C&T' → 'SAMSUNG C&T CORP' (69%)\n",
      "Review: 'KBFinancialGroup' → 'HANA FINANCIAL GROUP' (78%)\n",
      "Review: 'HANAFINANCIALGR' → 'HANA FINANCIAL GROUP' (63%)\n",
      "Review: 'Hanssem' → 'HANON SYSTEMS' (70%)\n",
      "Review: 'LG Uplus' → 'LG UPLUS CORP' (76%)\n",
      "Review: 'Celltrion' → 'Celltrion, Inc.' (82%)\n",
      "Review: 'DB HiTek' → 'DB HiTek Co Ltd' (70%)\n",
      "Review: 'SK Innovation' → 'SK INNOVATION CO LTD' (79%)\n",
      "Review: 'Exxon Mobil Corporation' → 'Exxon Mobil Corp' (82%)\n",
      "Review: 'Corning Incorporated' → 'Corning Inc' (71%)\n",
      "Review: 'Duke Energy Corporation (Holdin' → 'Duke Energy Corp' (70%)\n",
      "Review: 'AT&T Inc.' → 'AT&T Inc' (80%)\n",
      "Review: 'Amphenol Corporation' → 'Amphenol Corp' (79%)\n",
      "Review: 'Bank of America Corporation' → 'Bank of America Corp' (85%)\n",
      "Review: 'Chevron Corporation' → 'Cigna Corporation' (78%)\n",
      "Review: 'Dollar General Corporation' → 'Dollar General Corp' (84%)\n",
      "Review: 'Expedia Group, Inc.' → 'Expedia Inc' (79%)\n",
      "Review: 'Goldman Sachs Group, Inc. (The)' → 'Goldman Sachs Group Inc/The' (87%)\n",
      "Review: 'Intel Corporation' → 'S-1 CORPORATION' (77%)\n",
      "Review: 'News Corporation' → 'S-1 CORPORATION' (87%)\n",
      "Review: 'Target Corporation' → 'Target Corp' (76%)\n",
      "Review: 'Wells Fargo & Company' → 'Wells Fargo & Co' (85%)\n",
      "Review: 'LOTTE Fine Chem' → 'LOTTE Fine Chemical Co Ltd' (73%)\n",
      "Review: 'Kimberly-Clark Corporation' → 'Cigna Corporation' (65%)\n",
      "Review: 'QUANTA COMPUTER' → 'QUANTA COMPUTER INC' (88%)\n",
      "Review: 'HD HYUNDAI' → 'HYUNDAI MOTOR' (61%)\n",
      "Exact matches: 48/184\n",
      "Potential issues needing review: 102\n",
      "Unmatched names: 48\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import process, fuzz\n",
    "\n",
    "# Load files\n",
    "product_map = pd.read_csv(\"product_id_to_name.csv\")\n",
    "dividends = pd.read_csv(\"new_ticker_dividends.csv\")\n",
    "\n",
    "# Create a clean name matching dictionary\n",
    "product_names = product_map['product_name'].str.lower().str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "clean_names = {name: orig for name, orig in zip(product_names, product_map['product_name'])}\n",
    "\n",
    "def standardize_name(row):\n",
    "    # Skip exact matches\n",
    "    if row['Name'] in product_map['product_name'].values:\n",
    "        return row['Name']\n",
    "    \n",
    "    # Fuzzy match with preprocessing\n",
    "    clean_input = row['Name'].lower().replace(',', '').replace('.', '')\n",
    "    match, score = process.extractOne(clean_input, \n",
    "                                    clean_names.keys(),\n",
    "                                    scorer=fuzz.token_sort_ratio)\n",
    "    \n",
    "    # Validate match quality\n",
    "    if score >= 90:  # High confidence threshold\n",
    "        return clean_names[match]\n",
    "    elif score >= 60:  # Medium confidence - flag for review\n",
    "        print(f\"Review: '{row['Name']}' → '{clean_names[match]}' ({score}%)\")\n",
    "        return f\"{clean_names[match]} (NEEDS REVIEW)\"\n",
    "    else:\n",
    "        return row['Name']\n",
    "\n",
    "# Apply standardization\n",
    "dividends['Standardized_Name'] = dividends.apply(standardize_name, axis=1)\n",
    "\n",
    "# Generate reports\n",
    "exact_matches = dividends[dividends['Name'] == dividends['Standardized_Name']]\n",
    "potential_issues = dividends[dividends['Standardized_Name'].str.contains(\"NEEDS REVIEW\")]\n",
    "unmatched = dividends[dividends['Standardized_Name'] == dividends['Name']]\n",
    "\n",
    "print(f\"Exact matches: {len(exact_matches)}/{len(dividends)}\")\n",
    "print(f\"Potential issues needing review: {len(potential_issues)}\")\n",
    "print(f\"Unmatched names: {len(unmatched)}\")\n",
    "\n",
    "# Export results\n",
    "dividends.to_csv(\"standardized_dividends.csv\", index=False)\n",
    "potential_issues.to_csv(\"needs_review.csv\", index=False)\n",
    "unmatched.to_csv(\"unmatched_names.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab16f3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:19: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:19: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/tmp/ipykernel_37158/1696431897.py:19: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  transactions['PORTFOLIO_ID'].str.extract('(\\d+)')[0],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Results saved to CSV files.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "def load_data():\n",
    "    # Load datasets with proper CSV handling\n",
    "    transactions = pd.read_csv(\n",
    "        \"transaction_path.csv\",\n",
    "        parse_dates=['T_DATE'],\n",
    "        quoting=csv.QUOTE_ALL,\n",
    "        engine='python',\n",
    "    )\n",
    "    products = pd.read_csv(\"product_id_to_name.csv\")\n",
    "    dividends = pd.read_csv(\"standardized_dividends.csv\")\n",
    "    \n",
    "    # Clean portfolio_id column\n",
    "    transactions['PORTFOLIO_ID'] = pd.to_numeric(\n",
    "        transactions['PORTFOLIO_ID'].str.extract('(\\d+)')[0],\n",
    "        errors='coerce'\n",
    "    ).fillna(0).astype(int)\n",
    "    \n",
    "    # Create mappings\n",
    "    id_to_name = dict(zip(products['product_id'], products['product_name']))\n",
    "    name_to_id = {v: k for k, v in id_to_name.items()}\n",
    "    \n",
    "    return transactions, dividends, id_to_name, name_to_id\n",
    "\n",
    "def process_inventory(transactions):\n",
    "    # Filter and prepare transactions\n",
    "    inv_transactions = transactions[\n",
    "        (transactions['TRANSACTION_TYPE'].isin(['INVESTMENT', 'STOCK_SPLIT'])) &\n",
    "        (transactions['TYPE'].isin(['BUY', 'SELL']))\n",
    "    ].copy()\n",
    "    \n",
    "    # Convert relevant columns\n",
    "    inv_transactions['PRODUCT_ID'] = pd.to_numeric(\n",
    "        inv_transactions['PRODUCT_ID'], errors='coerce'\n",
    "    ).fillna(0).astype(int)\n",
    "    \n",
    "    inv_transactions['UNIT'] = pd.to_numeric(\n",
    "        inv_transactions['UNIT'], errors='coerce'\n",
    "    ).fillna(0)\n",
    "    \n",
    "    # Sort by date and product\n",
    "    inv_transactions = inv_transactions.sort_values(['PRODUCT_ID', 'PORTFOLIO_ID', 'T_DATE'])\n",
    "    \n",
    "    return inv_transactions\n",
    "\n",
    "def handle_stock_splits(inv_transactions):\n",
    "    # Process stock splits using safe regex parsing\n",
    "    splits = inv_transactions[inv_transactions['TRANSACTION_TYPE'] == 'STOCK_SPLIT']\n",
    "    split_adjustments = defaultdict(float)\n",
    "    \n",
    "    for _, row in splits.iterrows():\n",
    "        if pd.isna(row['NOTES']):\n",
    "            continue\n",
    "            \n",
    "        # Extract split ratio using regex\n",
    "        match = re.search(r'@(\\d+):(\\d+)', row['NOTES'])\n",
    "        if match:\n",
    "            _, new = map(int, match.groups())\n",
    "            split_adjustments[row['PRODUCT_ID']] = new\n",
    "        else:\n",
    "            print(f\"Warning: Invalid split format in transaction {row['TRANSACTION_ID']}\")\n",
    "    \n",
    "    return split_adjustments\n",
    "\n",
    "def calculate_inventory(inv_transactions, split_adjustments):\n",
    "    # Track inventory with split adjustments\n",
    "    inventory = defaultdict(lambda: defaultdict(float))\n",
    "    history = []\n",
    "\n",
    "    for _, row in inv_transactions.iterrows():\n",
    "        product_id = row['PRODUCT_ID']\n",
    "        portfolio = row['PORTFOLIO_ID']\n",
    "        units = row['UNIT']\n",
    "        action = row['TYPE']\n",
    "        date = row['T_DATE']\n",
    "        \n",
    "        # Apply stock split adjustments\n",
    "        if split_ratio := split_adjustments.get(product_id):\n",
    "            inventory[product_id][portfolio] *= split_ratio\n",
    "            split_adjustments.pop(product_id)  # Prevent reapplying\n",
    "        \n",
    "        # Update inventory\n",
    "        if action == 'BUY':\n",
    "            inventory[product_id][portfolio] += units\n",
    "        elif action == 'SELL':\n",
    "            inventory[product_id][portfolio] = max(0, inventory[product_id][portfolio] - units)\n",
    "        \n",
    "        history.append({\n",
    "            'Date': date.date(),\n",
    "            'Product_ID': product_id,\n",
    "            'Portfolio_ID': portfolio,\n",
    "            'Transaction_Type': action,\n",
    "            'Units': units,\n",
    "            'Cumulative_Quantity': inventory[product_id][portfolio]\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(history)\n",
    "\n",
    "def calculate_dividends(holdings_df, dividends_df, name_to_id):\n",
    "    dividend_payments = []\n",
    "    \n",
    "    # Convert holdings date to datetime\n",
    "    holdings_df['Date'] = pd.to_datetime(holdings_df['Date'])\n",
    "    \n",
    "    for _, div_row in dividends_df.iterrows():\n",
    "        product_name = div_row['Standardized_Name']\n",
    "        if (product_id := name_to_id.get(product_name)) is None:\n",
    "            continue\n",
    "            \n",
    "        # Process all dividend columns\n",
    "        for i in range(1, 7):\n",
    "            date_col = f'Dividend_{i}_Date'\n",
    "            amount_col = f'Dividend_{i}_Amount'\n",
    "            \n",
    "            if pd.notna(div_row[date_col]) and pd.notna(div_row[amount_col]):\n",
    "                div_date = pd.to_datetime(div_row[date_col])  # Keep as datetime64\n",
    "                div_amount = div_row[amount_col]\n",
    "                \n",
    "                # Filter holdings with proper datetime comparison\n",
    "                holdings = holdings_df[\n",
    "                    (holdings_df['Product_ID'] == product_id) &\n",
    "                    (holdings_df['Date'] <= div_date)\n",
    "                ]\n",
    "                \n",
    "                if not holdings.empty:\n",
    "                    latest_holding = holdings.sort_values('Date').iloc[-1]\n",
    "                    payment = latest_holding['Cumulative_Quantity'] * div_amount\n",
    "                    \n",
    "                    dividend_payments.append({\n",
    "                        'Product_ID': product_id,\n",
    "                        'Product_Name': product_name,\n",
    "                        'Dividend_Date': div_date.strftime('%Y-%m-%d'),  # Format for output\n",
    "                        'Shares_Held': latest_holding['Cumulative_Quantity'],\n",
    "                        'Dividend_per_Share': div_amount,\n",
    "                        'Total_Payment': payment\n",
    "                    })\n",
    "    \n",
    "    return pd.DataFrame(dividend_payments)\n",
    "\n",
    "def main():\n",
    "    # Load and process data\n",
    "    transactions, dividends, id_to_name, name_to_id = load_data()\n",
    "    inv_transactions = process_inventory(transactions)\n",
    "    \n",
    "    # Handle stock splits\n",
    "    split_adjustments = handle_stock_splits(inv_transactions)\n",
    "    \n",
    "    # Calculate inventory history\n",
    "    inventory_history = calculate_inventory(inv_transactions, split_adjustments)\n",
    "    \n",
    "    # Calculate dividend payments\n",
    "    dividend_results = calculate_dividends(inventory_history, dividends, name_to_id)\n",
    "    \n",
    "    # Save results\n",
    "    inventory_history.to_csv('inventory_history_detailed.csv', index=False)\n",
    "    dividend_results.to_csv('dividend_payments_complete.csv', index=False)\n",
    "    print(\"Processing complete. Results saved to CSV files.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
