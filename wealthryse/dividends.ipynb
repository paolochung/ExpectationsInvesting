{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40423fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$6837.HK: possibly delisted; no timezone found\n",
      "$SFUN: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing YY: HTTP Error 404: \n",
      "Error processing 8299.TW: HTTP Error 404: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$WUBA: possibly delisted; no timezone found\n",
      "$CTRP: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 5347.TW: HTTP Error 404: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$FTR: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 329180..KS: HTTP Error 404: \n",
      "Successfully saved to ticker_dividends_wide.csv\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Load Excel file\n",
    "df = pd.read_excel(\"dividend_update6.11.xlsx\", sheet_name=\"dividend_update6.11\")\n",
    "\n",
    "def clean_ticker(ticker):\n",
    "    ticker = str(ticker).replace(\" \", \"\")\n",
    "    if ticker.upper().endswith(\"HK\"):\n",
    "        code = ticker[:-2].strip()\n",
    "        padded_code = code.zfill(4)\n",
    "        return f\"{padded_code}.HK\"\n",
    "    elif ticker.upper().endswith(\"KS\"):\n",
    "        return f\"{ticker[:-2]}.KS\"\n",
    "    elif ticker.upper().endswith(\"TT\"):\n",
    "        return f\"{ticker[:-2]}.TW\"\n",
    "    elif ticker.upper().endswith(\"US\"):\n",
    "        return ticker[:-2]\n",
    "    else:\n",
    "        return ticker\n",
    "\n",
    "df[\"Cleaned_Ticker\"] = df[\"ticker\"].apply(clean_ticker)\n",
    "\n",
    "ticker_dividends = {}\n",
    "ticker_names = {}\n",
    "start_date = \"2017-01-01\"\n",
    "end_date = \"2025-06-01\"\n",
    "\n",
    "for ticker in df[\"Cleaned_Ticker\"].unique():\n",
    "    try:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        time.sleep(1)\n",
    "        # Get company name (shortName preferred, fallback to longName, else ticker)\n",
    "        info = stock.info\n",
    "        name = info.get(\"shortName\") or info.get(\"longName\") or ticker\n",
    "        ticker_names[ticker] = name\n",
    "\n",
    "        # Get dividends and filter by date\n",
    "        dividends = stock.dividends\n",
    "        if not dividends.empty:\n",
    "            dividends = dividends[(dividends.index >= start_date) & (dividends.index <= end_date)]\n",
    "            if not dividends.empty:\n",
    "                sorted_dividends = sorted(\n",
    "                    [(date.strftime(\"%Y-%m-%d\"), round(amount, 4))\n",
    "                     for date, amount in dividends.items()],\n",
    "                    key=lambda x: x[0]\n",
    "                )\n",
    "                ticker_dividends[ticker] = sorted_dividends\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ticker}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "max_dividends = max(len(d) for d in ticker_dividends.values()) if ticker_dividends else 0\n",
    "columns = [\"Ticker\", \"Name\"]\n",
    "for i in range(1, max_dividends + 1):\n",
    "    columns.extend([f\"Dividend_{i}_Date\", f\"Dividend_{i}_Amount\"])\n",
    "\n",
    "result_data = []\n",
    "for ticker, dividends in ticker_dividends.items():\n",
    "    row = [ticker, ticker_names.get(ticker, \"\")]\n",
    "    for date, amount in dividends:\n",
    "        row.extend([date, amount])\n",
    "    row += [None] * (max_dividends * 2 - len(dividends) * 2)\n",
    "    result_data.append(row)\n",
    "\n",
    "if result_data:\n",
    "    result_df = pd.DataFrame(result_data, columns=columns)\n",
    "    result_df.to_csv(\"ticker_dividends_wide.csv\", index=False)\n",
    "    print(\"Successfully saved to ticker_dividends_wide.csv\")\n",
    "else:\n",
    "    print(\"No dividend data found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4713a274",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_62387/518104704.py:81: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  holdings_timeline = df_holdings.groupby('Product').apply(get_holdings_at_date).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 missing dividend entries\n",
      "Output saved to missing_dividend_entries.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "from datetime import datetime\n",
    "\n",
    "# ==================================================================\n",
    "# 1. Load and Prepare Data\n",
    "# ==================================================================\n",
    "# Load security holdings\n",
    "df_holdings = pd.read_csv(\"Greater_China_2023_Track_Record.csv\", \n",
    "                         usecols=['Product', 'Currency', 'Contracts', 'Last Updated', 'Exchange Rate'],\n",
    "                         parse_dates=['Last Updated'])\n",
    "\n",
    "# Load dividend data\n",
    "df_dividends = pd.read_csv(\"new_ticker_dividends.csv\")\n",
    "\n",
    "existing_keys = set()\n",
    "for _, row in df_dividends.iterrows():\n",
    "    for i in range(1, 7):\n",
    "        date_col = f'Dividend_{i}_Date'\n",
    "        amt_col = f'Dividend_{i}_Amount'\n",
    "        if pd.notna(row[date_col]) and pd.notna(row[amt_col]):\n",
    "            key = (\n",
    "                row['Name'].strip().upper(),\n",
    "                pd.to_datetime(row[date_col]),\n",
    "                float(row[amt_col])\n",
    "            )\n",
    "            existing_keys.add(key)\n",
    "\n",
    "# ==================================================================\n",
    "# 2. Clean and Transform Dividend Data\n",
    "# ==================================================================\n",
    "# Melt dividend columns to long format\n",
    "dividend_cols = [col for col in df_dividends.columns if col.startswith('Dividend_')]\n",
    "df_dividends_long = pd.melt(\n",
    "    df_dividends,\n",
    "    id_vars=['Ticker', 'Name'],\n",
    "    value_vars=dividend_cols,\n",
    "    var_name='Dividend_Type',\n",
    "    value_name='Value'\n",
    ")\n",
    "\n",
    "# Separate dates and amounts\n",
    "df_dates = df_dividends_long[df_dividends_long['Dividend_Type'].str.contains('Date')]\n",
    "df_amounts = df_dividends_long[df_dividends_long['Dividend_Type'].str.contains('Amount')]\n",
    "\n",
    "# Merge clean dividend data\n",
    "df_dividends_clean = pd.merge(\n",
    "    df_dates.rename(columns={'Value': 'Ex-Date'}),\n",
    "    df_amounts.rename(columns={'Value': 'Dividend'}),\n",
    "    left_on=['Ticker', 'Name', df_dates.index],\n",
    "    right_on=['Ticker', 'Name', df_amounts.index]\n",
    ").dropna()\n",
    "\n",
    "# Convert dates and filter\n",
    "df_dividends_clean['Ex-Date'] = pd.to_datetime(df_dividends_clean['Ex-Date'])\n",
    "df_dividends_clean = df_dividends_clean[df_dividends_clean['Ex-Date'] >= '2024-01-01']\n",
    "\n",
    "# ==================================================================\n",
    "# 3. Match Security Names\n",
    "# ==================================================================\n",
    "def fuzzy_match(name, choices):\n",
    "    match, score, _ = process.extractOne(\n",
    "        name, choices, \n",
    "        scorer=fuzz.token_set_ratio,\n",
    "        score_cutoff=85\n",
    "    )\n",
    "    return match if score >= 85 else None\n",
    "\n",
    "security_names = df_holdings['Product'].unique()\n",
    "df_dividends_clean['Matched Security'] = df_dividends_clean['Name'].apply(\n",
    "    lambda x: fuzzy_match(x, security_names)\n",
    ")\n",
    "\n",
    "# ==================================================================\n",
    "# 4. Calculate Holdings at Dividend Dates\n",
    "# ==================================================================\n",
    "# Create holding timeline for each security\n",
    "def get_holdings_at_date(group):\n",
    "    return group.set_index('Last Updated')['Contracts'].resample('D').ffill()\n",
    "\n",
    "holdings_timeline = df_holdings.groupby('Product').apply(get_holdings_at_date).reset_index()\n",
    "\n",
    "df_dividends_clean = df_dividends_clean.rename(columns={'Matched Security': 'Product'})\n",
    "\n",
    "# Then proceed with the merge_asof\n",
    "merged = pd.merge_asof(\n",
    "    df_dividends_clean.sort_values('Ex-Date'),\n",
    "    holdings_timeline.sort_values('Last Updated').rename(columns={'Last Updated': 'Holding Date'}),\n",
    "    left_on='Ex-Date',\n",
    "    right_on='Holding Date',\n",
    "    by='Product',  # Now both DataFrames have 'Product'\n",
    "    direction='backward'\n",
    ")\n",
    "\n",
    "merged['Key'] = merged.apply(\n",
    "    lambda x: (\n",
    "        str(x['Name']).strip().upper(),\n",
    "        pd.to_datetime(x['Ex-Date']),\n",
    "        float(x['Dividend'])\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "merged['Exists'] = merged['Key'].isin(existing_keys)\n",
    "\n",
    "# ==================================================================\n",
    "# 5. Currency Conversion and Dividend Calculation\n",
    "# ==================================================================\n",
    "# Get currency info from holdings\n",
    "currency_map = df_holdings.drop_duplicates('Product').set_index('Product')['Currency']\n",
    "exchange_map = df_holdings.drop_duplicates('Product').set_index('Product')['Exchange Rate']\n",
    "\n",
    "currency_df = df_holdings[['Product', 'Currency']].drop_duplicates()\n",
    "exchange_df = df_holdings[['Product', 'Exchange Rate']].rename(columns={'Exchange Rate': 'FX Rate'}).drop_duplicates()\n",
    "\n",
    "# Merge using columns\n",
    "merged = merged.merge(currency_df, on='Product', how='left').merge(exchange_df, on='Product', how='left')\n",
    "\n",
    "# Convert dividends to holding currency\n",
    "merged['Converted Dividend'] = merged['Dividend'] * merged['FX Rate']\n",
    "merged.loc[merged['Currency'] == 'USD', 'Converted Dividend'] = merged['Dividend']\n",
    "\n",
    "# Calculate dividend amount\n",
    "merged['Dividend Payment'] = merged['Contracts'] * merged['Converted Dividend']\n",
    "\n",
    "# ==================================================================\n",
    "# 6. Identify Missing Entries\n",
    "# ==================================================================\n",
    "# Create composite key for comparison\n",
    "merged['Key'] = merged.apply(lambda x: f\"{x['Product']}|{x['Ex-Date']}|{x['Dividend']}\", axis=1)\n",
    "\n",
    "# Get existing entries from original data\n",
    "existing_keys = set()\n",
    "for _, row in df_dividends.iterrows():\n",
    "    for i in range(1,7):\n",
    "        date_col = f'Dividend_{i}_Date'\n",
    "        amt_col = f'Dividend_{i}_Amount'\n",
    "        if pd.notna(row[date_col]) and pd.notna(row[amt_col]):\n",
    "            key = f\"{row['Name']}|{row[date_col]}|{row[amt_col]}\"\n",
    "            existing_keys.add(key)\n",
    "\n",
    "merged['Exists'] = merged['Key'].isin(existing_keys)\n",
    "\n",
    "# ==================================================================\n",
    "# 7. Generate Final Output\n",
    "# ==================================================================\n",
    "output_cols = [\n",
    "    'Product', 'Ex-Date', 'Dividend', 'Currency',\n",
    "    'Converted Dividend', 'Contracts', 'Dividend Payment'\n",
    "]\n",
    "\n",
    "missing_dividends = merged[~merged['Exists']][output_cols]\n",
    "missing_dividends.to_csv('missing_dividend_entries.csv', index=False)\n",
    "\n",
    "print(f\"Found {len(missing_dividends)} missing dividend entries\")\n",
    "print(\"Output saved to missing_dividend_entries.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
